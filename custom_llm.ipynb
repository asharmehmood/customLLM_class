{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNTShD_5D6bz",
        "outputId": "6f7a1510-be99-4f6f-d01d-5f8f36159f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.28 (from langchain)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.24-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.31 langchain-text-splitters-0.0.1 langsmith-0.1.24 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.2.1.post1-py3-none-manylinux1_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2024.2.2)\n",
            "Installing collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.2.1.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRA8YbR7Ckiu",
        "outputId": "e616fa4f-74ac-4544-a9ca-2fe228240e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path already exists, delete the directory 'llm_model'\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Guidlines: Consider code language, problem statement and number of asked question.\n",
            "user question: give me code for binary search\n",
            "code:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'question': 'give me code for binary search', 'text': 'def bin_search(arr):\\n    low = 0 \\n    high= len ( arr ) - 1\\n\\n    while True :\\n        mid=(low+high)//2\\n\\n        if  arr[mid] == item   return \"found\" \\n        elif    x>item     then       hi=m-1  \\n        else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in a given range.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an array.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an array.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an array.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an array.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an array.\\n    code :\\n        def get_sum(a,b):\\n            if b<0 or  a > len ( arr ):\\n                return 0\\n\\n            elif    x>item     then       hi=m-1  \\n            else        lo      m+i\\nreturn False\\n\\n\\nuser question: find the sum of all numbers in an'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pydantic import Field\n",
        "from typing import List, Mapping, Optional, Any\n",
        "from langchain.llms.base import LLM\n",
        "from gpt4all import GPT4All\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "class MyGPT4ALL(LLM):\n",
        "    model_folder_path: str = Field(None, alias='model_folder_path')\n",
        "    model_name: str = Field(None, alias='model_name')\n",
        "    allow_download: bool = Field(None, alias='allow_download')\n",
        "\n",
        "    #optional parameters\n",
        "    backend:        Optional[str]   = 'llama'\n",
        "    temp:           Optional[float] = 0.5\n",
        "    max_tokens:     Optional[int]   = 500\n",
        "\n",
        "\n",
        "    #model instance\n",
        "    gpt4_model_instance:Any = None\n",
        "\n",
        "    def __init__(self, model_folder_path, model_name, allow_download, **kwargs):\n",
        "        super(MyGPT4ALL, self).__init__()\n",
        "        self.model_folder_path: str = model_folder_path\n",
        "        self.model_name = model_name\n",
        "        self.allow_download = allow_download\n",
        "\n",
        "        #if model is not already there, then download the model first\n",
        "        self.auto_download()\n",
        "\n",
        "        self.gpt4_model_instance = GPT4All(\n",
        "            model_name=self.model_name,\n",
        "            model_path=self.model_folder_path,\n",
        "            # model = '/content/drive/MyDrive/llm_model/replit-code-v1_5-3b-newbpe-q4_0.gguf'\n",
        "        )\n",
        "\n",
        "\n",
        "    def auto_download(self) -> None:\n",
        "        download_path = './llm_model'\n",
        "        if not os.path.exists(download_path):\n",
        "            os.makedirs(download_path, exist_ok=True)\n",
        "            model_folder_path = download_path\n",
        "            if self.allow_download:\n",
        "                try:\n",
        "                    url = f'http://gpt4all.io/models/{self.model_name}'\n",
        "                    response = requests.get(url, stream=True)\n",
        "\n",
        "                    with open(download_path+'/'+self.model_name, 'wb') as f:\n",
        "                        for chunk in tqdm(response.iter_content(chunk_size=8912)):\n",
        "                            if chunk: f.write(chunk)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"=> Download Failed. Error: {e}\")\n",
        "                    return\n",
        "\n",
        "                print(f\"=> Model: {self.model_name} downloaded\")\n",
        "\n",
        "            else:\n",
        "                print(\n",
        "                    f\"Model: {self.model_name} does not exists in {self.model_folder_path}\",\n",
        "                    \"Please either download the model by setting allow_download = True else change the path\"\n",
        "                )\n",
        "        else:\n",
        "            print(\"path already exists, delete the directory 'llm_model' if model is not there\")\n",
        "\n",
        "    @property\n",
        "    def _get_model_default_parameters(self):\n",
        "        return {\n",
        "            \"max_tokens\": self.max_tokens,\n",
        "            \"temp\": self.temp\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        return {\n",
        "            'model_name' : self.model_name,\n",
        "            'model_path' : self.model_folder_path,\n",
        "            'model_parameters': self._get_model_default_parameters\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return 'llama'\n",
        "\n",
        "    #this is the function which will be called when llm.invoke happens\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs) -> str:\n",
        "\n",
        "        params = {\n",
        "            **self._get_model_default_parameters,\n",
        "            **kwargs\n",
        "        }\n",
        "\n",
        "        resposne = self.gpt4_model_instance.generate(prompt, **params)\n",
        "        return resposne\n",
        "\n",
        "\n",
        "\n",
        "template = \"\"\"\n",
        "Guidlines: Consider code language, problem statement and number of asked question.\n",
        "user question: {question}\n",
        "code:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "#create custom llm object\n",
        "llm = MyGPT4ALL(model_folder_path='./llm_model',model_name='replit-code-v1_5-3b-newbpe-q4_0.gguf',allow_download=True)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True) #create llm chain\n",
        "\n",
        "#test the model\n",
        "response = llm_chain('give me code for binary search')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvwV39uuEP6b",
        "outputId": "aab4b3b9-8cfe-4bbd-9854-2b452e02cb86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'replit-code-v1_5-3b-newbpe-q4_0.gguf',\n",
              " 'model_path': '/content/drive/MyDrive/llm_model',\n",
              " 'model_parameters': {'max_tokens': 500, 'temp': 0.5}}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm._identifying_params"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
